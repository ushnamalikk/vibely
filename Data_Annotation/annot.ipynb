{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import faiss\n",
    "import regex as re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete!\n"
     ]
    }
   ],
   "source": [
    "embed_model = SentenceTransformer(\"Snowflake/snowflake-arctic-embed-m-v1.5\")\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"*insert your key here*\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_comments(video_comments):\n",
    "    filtered_comments = {}\n",
    "    for video_id, comments in video_comments.items():\n",
    "        filtered_comments[video_id] = [\n",
    "            comment for comment in comments\n",
    "            if is_valid_comment(comment)\n",
    "        ]\n",
    "    return filtered_comments\n",
    "\n",
    "def is_valid_comment(comment):\n",
    "    comment = comment.strip()\n",
    "\n",
    "    # Condition 1: Non-empty and >2 words\n",
    "    if len(comment.split()) <= 2:\n",
    "        return False\n",
    "\n",
    "    # Condition 2: Not purely numbers or special characters\n",
    "    if re.fullmatch(r\"[^\\w\\s]+\", comment) or re.fullmatch(r\"\\d+\", comment):\n",
    "        return False\n",
    "\n",
    "    # Condition 3: No excessive repeated characters (e.g., \"loooool\" or \"aaaaaa\")\n",
    "    if re.search(r\"(.)\\1{4,}\", comment):  # Four or more consecutive repeated characters\n",
    "        return False\n",
    "\n",
    "    # Condition 4: Not spam-like (e.g., \"www.example.com\" or repeated phrases)\n",
    "    if re.search(r\"(https?:\\/\\/|www\\.)\", comment):  # Links\n",
    "        return False\n",
    "    if re.search(r\"(buy now|subscribe|click here|free money)\", comment, re.IGNORECASE):  # Common spam phrases\n",
    "        return False\n",
    "\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_and_store_embeddings(comment_df, embed_model, save_path=\"embeddings_progress.pkl\"):\n",
    "    # Load existing progress if available\n",
    "    if os.path.exists(save_path):\n",
    "        with open(save_path, \"rb\") as f:\n",
    "            embeddings = pickle.load(f)\n",
    "        print(f\"Loaded progress from {save_path}\")\n",
    "    else:\n",
    "        embeddings = {}\n",
    "\n",
    "    total_comments = len(comment_df)\n",
    "    processed_comments = len(embeddings)\n",
    "    print(f\"Total comments to process: {total_comments}, already processed: {processed_comments}\")\n",
    "\n",
    "    # Flag to track if any new embeddings were added\n",
    "    new_embeddings_computed = False\n",
    "\n",
    "    for _, row in comment_df.iterrows():\n",
    "        comment = row[\"comment\"]\n",
    "        if comment in embeddings:\n",
    "            continue\n",
    "        try:\n",
    "            embeddings[comment] = embed_model.encode(comment)\n",
    "            processed_comments += 1\n",
    "            new_embeddings_computed = True  # Mark that new embeddings were added\n",
    "            if processed_comments % 2000 == 0:\n",
    "                print(f\"Processed {processed_comments}/{total_comments} comments\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing '{comment}': {e}\")\n",
    "\n",
    "    # Save only if new embeddings were computed\n",
    "    if new_embeddings_computed:\n",
    "        with open(save_path, \"wb\") as f:\n",
    "            pickle.dump(embeddings, f)\n",
    "        print(f\"Saved updated embeddings to {save_path}\")\n",
    "    else:\n",
    "        print(\"No new embeddings were computed. Skipping save.\")\n",
    "\n",
    "    print(f\"Embedding computation complete. Total embeddings: {len(embeddings)}\")\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Updated clustering function for exact clustering with cosine similarity\n",
    "def cluster_comments(video_comments, embeddings):\n",
    "\n",
    "    embeddings = np.array(embeddings).astype(\"float32\")\n",
    "    \n",
    "    faiss.normalize_L2(embeddings)  # Normalizes each vector to unit length\n",
    "\n",
    "    dim = embeddings.shape[1]\n",
    "    flat_index = faiss.IndexFlatIP(dim)\n",
    "    flat_index.add(embeddings)\n",
    "\n",
    "    # Perform clustering\n",
    "    clustering = faiss.Clustering(dim, n_clusters=min(len(embeddings), 377))\n",
    "    clustering.train(embeddings, flat_index)\n",
    "\n",
    "    # Assign comments to clusters\n",
    "    distances, cluster_indices = flat_index.search(embeddings, 1)\n",
    "    clustered_comments = defaultdict(list)\n",
    "    for i, cluster_idx in enumerate(cluster_indices.flatten()):\n",
    "        clustered_comments[cluster_idx].append(video_comments[i])\n",
    "    \n",
    "    return clustered_comments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_all_comments(embeddings_dict, n_clusters=25):\n",
    "    all_comments = list(embeddings_dict.keys())\n",
    "    embeddings = np.array([embeddings_dict[comment] for comment in all_comments]).astype(\"float32\")\n",
    "    faiss.normalize_L2(embeddings)\n",
    "\n",
    "    # Perform global clustering\n",
    "    dim = embeddings.shape[1]\n",
    "    flat_index = faiss.IndexFlatIP(dim)\n",
    "    flat_index.add(embeddings)\n",
    "\n",
    "    clustering = faiss.Clustering(dim, n_clusters)\n",
    "    clustering.train(embeddings, flat_index)\n",
    "\n",
    "    # Assign comments to clusters\n",
    "    _, cluster_indices = flat_index.search(embeddings, 1)\n",
    "    global_clusters = defaultdict(list)\n",
    "    for i, cluster_idx in enumerate(cluster_indices.flatten()):\n",
    "        global_clusters[cluster_idx].append(all_comments[i])\n",
    "\n",
    "    print(f\"Total clusters formed: {len(global_clusters)}\")\n",
    "    # for cluster_id, comments in global_clusters.items():\n",
    "    #     print(f\"Cluster {cluster_id}: {len(comments)} comments\")\n",
    "    return global_clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_classification(classification, save_path=\"classification.json\"):\n",
    "    with open(save_path, \"w\") as f:\n",
    "        json.dump(classification, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_centroid_representative(cluster_embeddings, comments):\n",
    "    # Compute the centroid of the cluster\n",
    "    centroid = np.mean(cluster_embeddings, axis=0)\n",
    "\n",
    "    # Find the embedding closest to the centroid\n",
    "    distances = np.linalg.norm(cluster_embeddings - centroid, axis=1)\n",
    "    closest_idx = np.argmin(distances)\n",
    "    \n",
    "    # Return the comment closest to the centroid\n",
    "    return comments[closest_idx]\n",
    "\n",
    "def classify_clusters(global_clusters, embeddings_dict):\n",
    "    classification_results = {}\n",
    "    prompt_template = \"\"\"You are tasked with categorizing a given music description into one of the following categories. Each description will only belong to one category. Read the description carefully and assign it to the most appropriate category based on the following guidelines:\n",
    "\n",
    "Music: The description focuses on anything related to the music itself. This includes:\n",
    "- How the music sounds (e.g., melody, tune, beat, harmony, or rhythm).\n",
    "- The vibe, energy, or mood of the music (e.g., relaxing, upbeat, groovy).\n",
    "- The quality or listenerâ€™s opinion of the music (e.g., â€œthe music is great,â€ â€œamazing beatâ€).\n",
    "\n",
    "Examples:\n",
    "- â€œIt was awesome.â€\n",
    "- â€œAlways bring tears to my eyes beautiful track.â€\n",
    "- â€œGODDDD!!!! What a sooothinggg beautifulll banger.â€\n",
    "\n",
    "Artist: The description mentions the artist or creator of the music and appreciates their singing quality. This includes:\n",
    "- Mentions of the artistâ€™s name or pronouns (e.g., â€œhe,â€ â€œshe,â€ â€œtheyâ€).\n",
    "- Opinions, praise, or criticism directed toward the artist (e.g., â€œthis artist is brilliantâ€).\n",
    "- Comments directly addressed to the artist or the creator of the audio.\n",
    "\n",
    "Examples:\n",
    "- â€œlove u sir.â€\n",
    "- â€œThe depth of voice and emotion is so HEART TOUCHING. Beautifully sung by Aima Begh.â€\n",
    "- â€œï¸such a magical voice.â€\n",
    "\n",
    "Ambiguous: The description contains phrases, words, or content that are unclear, incomplete, or donâ€™t make sense in the given context. This includes:\n",
    "- Random letters, symbols, or gibberish.\n",
    "- Words or phrases that do not convey a clear meaning.\n",
    "- Non-standard terms, slang, or ambiguous references.\n",
    "\n",
    "Examples:\n",
    "- â€œ@lm bohemia Dz ðŸ”¥.â€\n",
    "- â€œwhat my waat rat fat gaiaaaaðŸ‡§ðŸ‡©â€\n",
    "- â€œ3 like ha Bhi.â€\n",
    "\n",
    "Others: Any description that does not clearly fit into the Music, Artist, or Ambiguous categories. This includes:\n",
    "- General observations not specifically about the music, artist, or ambiguous phrases.\n",
    "\n",
    "Examples:\n",
    "- â€œOld days are gone.â€\n",
    "- â€œIs that earbud in his ear?â€\n",
    "- â€œOnly 277 views in 2 days.â€\n",
    "\n",
    "Instructions:\n",
    "For each music description:\n",
    "1. Read the description carefully.\n",
    "2. Compare it against the definitions and examples for each category.\n",
    "3. Assign the description to the most suitable category (Music, Artist, Ambiguous, Others).\n",
    "\n",
    "Response Format:\n",
    "â€œCategory: [Insert category name]â€\"\"\"\n",
    "\n",
    "    for cluster_id, comments in global_clusters.items():\n",
    "        cluster_embeddings = np.array([embeddings_dict[c] for c in comments])\n",
    "        representative = find_centroid_representative(cluster_embeddings, comments)\n",
    "\n",
    "        try:\n",
    "            # Generate classification via GPT-4\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": prompt_template},\n",
    "                    {\"role\": \"user\", \"content\": f\"Comment: {representative}\"}\n",
    "                ],\n",
    "                max_tokens=100\n",
    "            )\n",
    "\n",
    "            # Extract the category from the response\n",
    "            label = response.choices[0].message.content.strip().replace(\"Category: \", \"\")\n",
    "\n",
    "            # Assign the category to all comments in the cluster\n",
    "            for comment in comments:\n",
    "                classification_results[comment] = label\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error classifying cluster {cluster_id}: {e}\")\n",
    "\n",
    "        print(f\"Cluster {cluster_id} classified as {label}\")\n",
    "        # break\n",
    "\n",
    "    return classification_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_comments_individually(comment_df):\n",
    "    classification_results = {}\n",
    "    prompt_template = \"\"\"You are tasked with categorizing a given music description into one of the following categories. Each description will only belong to one category. Read the description carefully and assign it to the most appropriate category based on the following guidelines:\n",
    "\n",
    "Music: The description focuses on anything related to the music itself. This includes:\n",
    "- How the music sounds (e.g., melody, tune, beat, harmony, or rhythm).\n",
    "- The vibe, energy, or mood of the music (e.g., relaxing, upbeat, groovy).\n",
    "- The quality or listenerâ€™s opinion of the music (e.g., â€œthe music is great,â€ â€œamazing beatâ€).\n",
    "\n",
    "Examples:\n",
    "- â€œIt was awesome.â€\n",
    "- â€œAlways bring tears to my eyes beautiful track.â€\n",
    "- â€œGODDDD!!!! What a sooothinggg beautifulll banger.â€\n",
    "\n",
    "Artist: The description mentions the artist or creator of the music and appreciates their singing quality. This includes:\n",
    "- Mentions of the artistâ€™s name or pronouns (e.g., â€œhe,â€ â€œshe,â€ â€œtheyâ€).\n",
    "- Opinions, praise, or criticism directed toward the artist (e.g., â€œthis artist is brilliantâ€).\n",
    "- Comments directly addressed to the artist or the creator of the audio.\n",
    "\n",
    "Examples:\n",
    "- â€œlove u sir.â€\n",
    "- â€œThe depth of voice and emotion is so HEART TOUCHING. Beautifully sung by Aima Begh.â€\n",
    "- â€œï¸such a magical voice.â€\n",
    "\n",
    "Ambiguous: The description contains phrases, words, or content that are unclear, incomplete, or donâ€™t make sense in the given context. This includes:\n",
    "- Random letters, symbols, or gibberish.\n",
    "- Words or phrases that do not convey a clear meaning.\n",
    "- Non-standard terms, slang, or ambiguous references.\n",
    "\n",
    "Examples:\n",
    "- â€œ@lm bohemia Dz ðŸ”¥.â€\n",
    "- â€œwhat my waat rat fat gaiaaaaðŸ‡§ðŸ‡©â€\n",
    "- â€œ3 like ha Bhi.â€\n",
    "\n",
    "Others: Any description that does not clearly fit into the Music, Artist, or Ambiguous categories. This includes:\n",
    "- General observations not specifically about the music, artist, or ambiguous phrases.\n",
    "\n",
    "Examples:\n",
    "- â€œOld days are gone.â€\n",
    "- â€œIs that earbud in his ear?â€\n",
    "- â€œOnly 277 views in 2 days.â€\n",
    "\n",
    "Instructions:\n",
    "For each music description:\n",
    "1. Read the description carefully.\n",
    "2. Compare it against the definitions and examples for each category.\n",
    "3. Assign the description to the most suitable category (Music, Artist, Ambiguous, Others).\n",
    "\n",
    "Response Format:\n",
    "â€œCategory: [Insert category name]â€\"\"\"\n",
    "\n",
    "    for _, row in comment_df.iterrows():\n",
    "        comment = row[\"comment\"]\n",
    "        try:\n",
    "            # Generate classification via GPT-4\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": prompt_template},\n",
    "                    {\"role\": \"user\", \"content\": f\"Comment: {comment}\"}\n",
    "                ],\n",
    "                max_tokens=100\n",
    "            )\n",
    "\n",
    "            # Extract the category from the response\n",
    "            label = response.choices[0].message.content.strip().replace(\"Category: \", \"\")\n",
    "            # comment_df[\"individual_label\"] = label\n",
    "            classification_results[comment] = label\n",
    "            # print(f\"Comment '{comment}' classified as {label}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error classifying comment '{comment}': {e}\")\n",
    "\n",
    "        # map the comment to the label\n",
    "        comment_df[\"individual_label\"] = comment_df[\"comment\"].map(classification_results)\n",
    "\n",
    "        # break\n",
    "\n",
    "    return classification_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video_comments(video_df, embed_model, output_file=\"classified_comments5.json\"):\n",
    "    #Step 0: Filter out empty or irrelevant comments\n",
    "    # print(\"Filtering comments...\")\n",
    "    # video_df = filter_comments(video_df)\n",
    "\n",
    "    #Step 1: Compute embeddings and save progress\n",
    "    print(\"Computing embeddings...\")\n",
    "    embeddings_dict = compute_and_store_embeddings(video_df, embed_model)\n",
    "\n",
    "    #Step 2: Process each video for clustering and classification\n",
    "    print(\"Clustering comments...\")\n",
    "    clusters = cluster_all_comments(embeddings_dict)\n",
    "\n",
    "    #Step 3: Classify clusters\n",
    "    print(\"Classifying clusters...\")\n",
    "    clusters = classify_clusters(clusters, embeddings_dict)\n",
    "\n",
    "    #Step 4: Map cluster labels to comment dataframe\n",
    "    print(\"Mapping cluster labels to comments...\")\n",
    "    video_df[\"cluster_label5\"] = video_df[\"comment\"].map(clusters)\n",
    "\n",
    "    #Step 4: Save final results to a file\n",
    "    print(\"Saving results...\")\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(clusters, f, indent=2)\n",
    "    \n",
    "    # saving df to csv\n",
    "    video_df.to_csv(\"classified_comments.csv\", index=False)\n",
    "    \n",
    "    print(f\"Final results saved to {output_file}\")\n",
    "\n",
    "    return clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video_comments_individually(video_df, output_file=\"classified_comments_individually.json\"):\n",
    "    \n",
    "    cluster_resul = classify_comments_individually(video_df)\n",
    "\n",
    "    # save the df to csv\n",
    "    video_df.to_csv(\"classified_comments_new.csv\", index=False)\n",
    "\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(cluster_resul, f, indent=2)\n",
    "\n",
    "    print(f\"Final results saved to {output_file}\")\n",
    "\n",
    "    return cluster_resul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results saved to classified_comments_individually.json\n"
     ]
    }
   ],
   "source": [
    "# create a new df\n",
    "df = pd.read_csv(\"classified_comments.csv\")\n",
    "\n",
    "\n",
    "# classified_clusters = process_video_comments(df, embed_model)\n",
    "classified_clusters = process_video_comments_individually(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
